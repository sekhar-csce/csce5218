{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYiZq0X2oB5t"
   },
   "source": [
    "# **CSCE 5218 / CSCE 4930 Deep Learning**\n",
    "\n",
    "# **HW1a The Perceptron** (20 pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGVmKzgG2Ium",
    "outputId": "4cc2ca21-861a-4fba-a38c-83e3ec04bec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1\tA2\tA3\tA4\tA5\tA6\tA7\tA8\tA9\tA10\tA11\tA12\tA13\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 11244  100 11244    0     0  10305      0  0:00:01  0:00:01 --:--:-- 11034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\t1\t0\t0\t0\t0\t0\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t1\t0\t1\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t0\t1\t0\t0\t1\t0\t1\t0\t1\t1\t1\t1\t0\n",
      "0\t1\t0\t0\t0\t0\t0\t1\t1\t1\t1\t1\t1\t0\n",
      "0\t1\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t0\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t1\t1\t0\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t0\t0\t1\t0\t1\t0\t1\t0\t1\t0\n",
      "1\t0\t1\t1\t1\t0\t0\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t0\t1\t0\t1\t1\t1\t1\t1\t1\t1\t1\n",
      "0\t0\t1\t1\t0\t0\t1\t0\t0\t1\t1\t1\t1\t0\n",
      "1\t0\t1\t1\t0\t0\t1\t1\t0\t1\t0\t0\t1\t1\n",
      "0\t0\t1\t1\t0\t0\t0\t0\t1\t0\t1\t1\t1\t0\n",
      "1\t0\t0\t0\t0\t0\t1\t0\t1\t1\t0\t1\t1\t0\n",
      "0\t1\t1\t1\t1\t1\t0\t0\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t0\t0\t1\t0\t1\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t0\t0\t0\t0\t1\t1\t0\t1\t1\t1\t1\t1\t0\n",
      "1\t0\t0\t1\t0\t1\t0\t1\t1\t0\t0\t1\t1\t0\n",
      "0\t0\t1\t1\t0\t1\t1\t0\t0\t0\t0\t1\t1\t0\n",
      "1\t1\t1\t0\t0\t1\t1\t1\t1\t1\t0\t1\t1\t1\n",
      "0\t1\t1\t1\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "0\t0\t1\t1\t0\t1\t0\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t0\t0\t1\t0\t1\t1\t1\t1\t0\t0\t1\t1\t0\n",
      "0\t0\t1\t0\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "1\t0\t1\t0\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t0\t0\t1\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t0\t0\t0\t1\t1\t1\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t0\t0\t0\t0\t0\t1\t1\t1\t1\t1\t0\t1\t0\n",
      "0\t0\t1\t1\t0\t1\t0\t1\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t1\t0\t0\t0\t1\t1\t1\t1\t0\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t1\t1\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t1\t0\t0\t0\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t1\t0\t0\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t0\t1\t0\t1\t1\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t1\t0\t1\t0\t1\t1\t0\t0\t0\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t0\t0\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t1\t1\t1\t0\t0\t1\t1\t1\t1\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t1\t0\n",
      "1\t0\t1\t0\t1\t0\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "1\t1\t1\t1\t1\t0\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "1\t1\t1\t0\t1\t0\t1\t0\t1\t1\t1\t0\t1\t1\n",
      "1\t0\t1\t1\t1\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "0\t1\t1\t0\t1\t0\t0\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t0\t1\t1\t1\t0\t0\t0\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t0\t1\t1\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t0\t1\t0\t1\t0\t0\t0\t0\t0\t0\t1\t1\t1\n",
      "1\t0\t0\t1\t0\t1\t0\t0\t0\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t1\t1\t1\t0\t1\t1\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t1\t1\t0\t0\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t0\t0\t1\t0\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t0\t1\t0\t1\t0\t1\t1\t1\t1\t1\n",
      "0\t1\t0\t0\t1\t1\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t1\t1\t1\t1\t1\t0\t1\t0\n",
      "0\t0\t1\t1\t1\t1\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "0\t1\t0\t0\t0\t0\t1\t0\t0\t1\t0\t1\t1\t0\n",
      "0\t0\t1\t0\t1\t1\t0\t0\t0\t1\t1\t0\t1\t0\n",
      "1\t0\t1\t0\t1\t0\t0\t0\t1\t0\t0\t1\t1\t1\n",
      "0\t0\t0\t1\t0\t1\t0\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t1\t0\t0\t1\t0\t1\t1\t0\t0\t1\t1\t1\t0\n",
      "0\t0\t1\t0\t1\t1\t1\t0\t0\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t0\t0\t1\t1\t1\t1\t1\t0\t1\t0\n",
      "1\t0\t1\t0\t0\t0\t0\t1\t1\t1\t1\t0\t1\t1\n",
      "0\t1\t0\t1\t1\t1\t0\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t1\t0\t0\t1\t0\t0\t1\t1\t0\t1\t1\n",
      "0\t1\t0\t1\t0\t1\t1\t1\t0\t0\t0\t0\t1\t0\n",
      "1\t0\t1\t0\t1\t0\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t1\t0\t0\t1\t1\t1\t0\t0\t1\t1\t1\t1\t1\n",
      "1\t0\t1\t0\t1\t0\t1\t1\t0\t1\t1\t0\t1\t0\n",
      "1\t1\t0\t1\t0\t0\t0\t0\t0\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t0\t1\t0\t0\t0\t1\t0\t0\t1\t0\n",
      "1\t0\t1\t1\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\n",
      "1\t1\t0\t0\t1\t0\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "1\t0\t1\t0\t1\t1\t1\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t0\t1\t1\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t0\t1\t1\t0\t1\t1\t1\t0\t0\t1\t0\n",
      "1\t0\t0\t1\t1\t1\t0\t1\t0\t0\t0\t0\t1\t0\n",
      "1\t0\t1\t1\t1\t0\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t0\t0\t0\t1\t1\t1\t1\t0\n",
      "0\t1\t1\t0\t0\t0\t1\t0\t1\t1\t1\t0\t1\t1\n",
      "1\t1\t0\t0\t1\t0\t1\t0\t0\t1\t0\t0\t1\t0\n",
      "1\t0\t0\t0\t1\t1\t0\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t1\t1\t0\t0\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t1\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t1\t1\t0\t1\t0\t0\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t1\t0\t1\t0\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t1\t1\t0\t0\t1\t0\t1\t0\t1\t0\t0\t1\t0\n",
      "1\t1\t0\t0\t1\t0\t1\t0\t1\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t0\t0\t1\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t1\t1\t0\t1\t0\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t1\t0\t1\t0\t1\t0\t1\t1\t1\t1\t1\n",
      "0\t0\t0\t0\t1\t1\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t1\t1\t1\t0\t0\t0\t1\t1\n",
      "1\t0\t0\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t1\t0\t1\t0\t0\t1\t1\t0\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t0\t0\t0\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "0\t0\t0\t0\t0\t1\t1\t1\t0\t0\t1\t0\t1\t0\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t1\t1\t0\t0\t0\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t1\t0\t0\t1\t0\t0\t1\t1\t1\t0\t0\t1\t0\n",
      "1\t1\t1\t0\t1\t1\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t1\t0\t0\t1\t1\t0\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\t1\t1\n",
      "0\t0\t0\t0\t0\t0\t1\t1\t0\t0\t0\t0\t1\t0\n",
      "1\t1\t1\t1\t1\t0\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "0\t1\t0\t1\t1\t0\t0\t0\t0\t0\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t1\t1\t1\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t0\t0\t1\t1\t0\t1\t1\t1\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t0\t0\t1\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t0\t0\t1\t0\t0\t0\t1\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t1\t1\t0\t1\t0\t0\t1\t0\n",
      "1\t0\t1\t0\t1\t0\t0\t1\t1\t0\t0\t1\t1\t0\n",
      "1\t0\t1\t0\t1\t0\t0\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t0\t1\t0\t0\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "0\t0\t0\t1\t1\t1\t1\t1\t0\t1\t0\t0\t1\t0\n",
      "1\t1\t1\t0\t0\t1\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t1\t0\t0\t0\t0\t0\t1\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t1\t1\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\n",
      "0\t0\t1\t0\t1\t1\t0\t1\t0\t1\t0\t1\t1\t1\n",
      "0\t1\t0\t0\t1\t0\t0\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t0\t1\t1\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t1\t1\t1\t1\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t0\t1\t1\t1\t1\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t0\t1\t0\t1\t1\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t1\t1\t0\t1\t1\t0\t0\t1\t1\t1\t0\n",
      "0\t0\t1\t0\t1\t1\t0\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t0\t0\t1\t1\t1\t1\t1\t1\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t0\t1\t1\t1\t1\t1\t1\t0\t1\t1\t1\n",
      "1\t1\t1\t1\t0\t0\t0\t1\t0\t0\t1\t1\t1\t0\n",
      "0\t1\t1\t1\t1\t0\t1\t0\t1\t1\t1\t1\t1\t1\n",
      "0\t0\t0\t0\t1\t1\t1\t1\t1\t1\t1\t0\t1\t0\n",
      "1\t1\t0\t0\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t0\t1\t1\t0\t1\t1\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t0\t0\t0\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t1\t1\t1\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "0\t1\t0\t0\t1\t1\t1\t0\t1\t0\t1\t0\t1\t1\n",
      "0\t0\t1\t1\t1\t1\t0\t0\t0\t1\t1\t1\t1\t0\n",
      "1\t1\t0\t1\t0\t1\t1\t0\t0\t0\t0\t1\t1\t1\n",
      "1\t1\t1\t1\t1\t0\t0\t0\t1\t0\t0\t0\t1\t1\n",
      "0\t1\t0\t1\t1\t1\t0\t1\t0\t1\t1\t1\t1\t1\n",
      "1\t0\t1\t1\t1\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t0\t0\t1\t0\t0\t0\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t1\t0\t0\t1\t1\t1\t1\t0\t0\t1\t1\n",
      "1\t0\t0\t1\t1\t1\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t0\t1\t1\t0\t0\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t0\t1\t0\t1\t1\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t1\t1\t1\t1\t0\t1\t1\t1\t1\t1\t1\n",
      "0\t1\t0\t1\t0\t0\t0\t0\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t0\t1\t1\t0\t0\t0\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t1\t1\t1\t0\t0\t1\t1\t0\n",
      "0\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\t1\t1\t0\n",
      "1\t1\t1\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t0\t1\t0\t0\t1\t0\t1\t1\t1\t0\t1\t1\t1\n",
      "1\t1\t1\t0\t0\t1\t1\t1\t0\t0\t0\t1\t1\t1\n",
      "0\t0\t0\t0\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\t0\t1\t0\n",
      "1\t1\t1\t1\t0\t0\t1\t1\t0\t0\t1\t1\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t1\t1\t1\t1\t0\t1\t1\t0\n",
      "0\t0\t1\t1\t0\t1\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "1\t0\t0\t1\t1\t0\t1\t1\t1\t0\t0\t0\t1\t1\n",
      "0\t0\t0\t0\t0\t0\t0\t0\t1\t1\t0\t1\t1\t0\n",
      "1\t1\t0\t0\t0\t1\t0\t0\t1\t1\t1\t1\t1\t1\n",
      "1\t0\t1\t0\t0\t0\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t0\t1\t0\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t0\t0\t0\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t0\t1\t0\t1\t0\t0\t1\t0\t1\t1\t0\n",
      "0\t0\t1\t0\t1\t1\t0\t0\t0\t0\t1\t0\t1\t0\n",
      "0\t0\t0\t0\t0\t1\t1\t1\t1\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t0\t1\t1\t0\t1\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t1\t0\t1\t1\t1\t0\t1\t1\t0\t1\t0\n",
      "1\t1\t0\t0\t0\t0\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t0\t1\t0\t1\t0\t0\t1\t0\t1\t1\t1\t1\t1\n",
      "1\t1\t0\t0\t0\t1\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t0\t1\t0\t0\t0\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t0\t0\t0\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t1\t0\t0\t0\t0\t0\t0\t0\t1\t0\n",
      "1\t0\t0\t1\t0\t1\t0\t0\t0\t1\t1\t1\t1\t0\n",
      "1\t0\t1\t1\t1\t1\t1\t1\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t0\t1\t1\t0\t1\t1\t1\t1\t1\t0\t1\t0\n",
      "0\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\t1\t1\t0\n",
      "0\t0\t0\t1\t0\t0\t0\t0\t1\t0\t1\t0\t1\t1\n",
      "1\t1\t0\t1\t1\t0\t1\t0\t1\t1\t0\t0\t1\t0\n",
      "1\t1\t1\t1\t1\t1\t0\t0\t0\t1\t1\t0\t1\t1\n",
      "1\t0\t1\t1\t1\t0\t0\t1\t0\t0\t0\t1\t1\t1\n",
      "1\t1\t0\t1\t1\t0\t0\t0\t0\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t0\t0\t1\t1\t0\t1\t1\t1\t1\t1\t0\n",
      "0\t0\t1\t0\t1\t0\t0\t1\t0\t0\t1\t1\t1\t1\n",
      "1\t1\t0\t0\t1\t0\t1\t1\t0\t1\t0\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t1\t1\t0\t1\t0\t1\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t0\t0\t1\t0\t0\t1\t0\t0\t1\t1\t0\n",
      "0\t0\t1\t1\t1\t0\t0\t1\t1\t1\t0\t1\t1\t1\n",
      "1\t1\t1\t1\t0\t1\t0\t0\t0\t0\t0\t1\t1\t0\n",
      "1\t1\t1\t0\t1\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t1\t1\t1\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t0\t0\t0\t1\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\t1\t1\t1\n",
      "1\t1\t1\t0\t0\t1\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t1\t1\t1\t1\t1\t1\t0\t1\t1\t0\t0\t1\t0\n",
      "1\t0\t0\t1\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t0\t1\t1\t1\t0\t1\t1\t0\t0\t0\t0\t1\t0\n",
      "1\t1\t0\t0\t1\t1\t1\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t0\t1\t0\t1\t1\t1\t0\t0\t1\t0\n",
      "1\t0\t1\t1\t0\t0\t0\t0\t1\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t1\t1\t1\t0\t1\t0\t0\t1\t1\t1\t0\n",
      "0\t1\t0\t0\t1\t0\t1\t1\t1\t0\t1\t0\t1\t1\n",
      "0\t0\t0\t1\t0\t1\t0\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\t1\t1\n",
      "0\t1\t0\t0\t1\t0\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t0\t1\t0\t0\t0\t1\t1\t0\t1\t1\t0\n",
      "0\t0\t1\t1\t1\t1\t1\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t1\t0\t0\t1\t0\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t0\t1\t1\t0\t0\t1\t1\t1\t1\t0\n",
      "0\t1\t0\t1\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t0\t1\t0\t0\t0\t0\t1\t0\t1\t0\n",
      "1\t1\t1\t0\t1\t1\t0\t0\t1\t0\t1\t0\t1\t1\n",
      "0\t0\t1\t0\t0\t0\t0\t1\t1\t1\t0\t1\t1\t1\n",
      "0\t1\t1\t0\t1\t1\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t0\t0\t0\t1\t1\t1\t1\t1\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t0\t0\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t1\t1\t1\t0\t0\t0\t1\t0\t0\t1\t0\n",
      "1\t0\t0\t0\t1\t0\t1\t1\t0\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t0\t1\t1\t0\t1\t0\t1\t0\t1\t1\t0\n",
      "1\t0\t1\t1\t1\t0\t0\t0\t0\t0\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t1\t0\t1\t0\t1\t0\t1\t1\n",
      "1\t1\t0\t1\t1\t1\t1\t0\t0\t1\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t0\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t1\t1\t0\t0\t1\t1\t1\t0\t1\t1\t1\n",
      "0\t0\t1\t0\t1\t1\t0\t0\t1\t1\t1\t1\t1\t1\n",
      "0\t0\t1\t1\t1\t1\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "0\t0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t0\t1\t1\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "0\t0\t0\t1\t1\t1\t1\t1\t1\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t1\t0\t1\t1\t0\t0\t0\t1\t0\t1\t0\n",
      "1\t0\t1\t1\t1\t1\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "1\t1\t1\t0\t0\t1\t0\t1\t1\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t0\t0\t1\t1\t0\t1\t0\t1\t0\t1\t1\n",
      "0\t1\t1\t0\t0\t0\t0\t1\t0\t1\t0\t0\t1\t0\n",
      "1\t1\t0\t0\t1\t0\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t0\t1\t0\t0\t1\t0\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t1\t1\t1\t0\t0\t0\t0\t1\t0\t1\t0\n",
      "1\t1\t0\t1\t0\t0\t0\t0\t0\t1\t0\t0\t1\t1\n",
      "1\t0\t0\t1\t1\t0\t1\t1\t0\t1\t0\t1\t1\t0\n",
      "0\t1\t1\t1\t1\t0\t0\t1\t0\t0\t1\t0\t1\t0\n",
      "1\t0\t0\t1\t1\t1\t0\t0\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t0\t0\t1\t1\t1\t1\t0\t0\t1\t1\t0\n",
      "0\t1\t1\t0\t0\t1\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "0\t1\t1\t0\t0\t1\t0\t0\t1\t0\t0\t1\t1\t0\n",
      "0\t1\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t1\t0\n",
      "1\t0\t0\t0\t0\t0\t1\t0\t0\t1\t1\t0\t1\t0\n",
      "1\t0\t1\t1\t0\t1\t0\t1\t0\t0\t1\t1\t1\t1\n",
      "0\t1\t1\t0\t0\t0\t0\t1\t0\t0\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\t1\t1\t0\n",
      "0\t0\t0\t1\t0\t0\t0\t0\t1\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t0\t1\t1\t1\t0\t1\t0\t1\t0\t1\t1\n",
      "0\t1\t0\t1\t0\t1\t0\t0\t0\t1\t1\t1\t1\t0\n",
      "0\t1\t0\t0\t0\t0\t1\t0\t1\t0\t0\t0\t1\t0\n",
      "1\t1\t1\t0\t1\t0\t0\t1\t1\t0\t1\t1\t1\t0\n",
      "0\t1\t0\t0\t1\t1\t1\t1\t0\t1\t1\t0\t1\t0\n",
      "1\t1\t0\t0\t1\t0\t1\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t1\t0\t0\t1\t1\t1\t0\t1\t1\t0\t1\t1\t0\n",
      "0\t0\t1\t1\t0\t0\t0\t0\t0\t1\t0\t0\t1\t0\n",
      "1\t0\t1\t1\t0\t0\t1\t0\t1\t0\t1\t0\t1\t1\n",
      "0\t0\t0\t1\t1\t0\t1\t1\t0\t1\t1\t1\t1\t1\n",
      "1\t0\t1\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\t1\n",
      "0\t1\t1\t0\t0\t0\t1\t0\t0\t0\t1\t0\t1\t1\n",
      "1\t0\t0\t0\t1\t1\t1\t1\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t1\t1\t1\t1\t1\t1\t1\t0\t0\t1\t1\n",
      "0\t1\t0\t1\t1\t0\t1\t1\t1\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t1\t0\t0\t0\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t1\t1\t1\t1\t0\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t0\t1\t1\t1\t0\t1\t0\t0\t1\t1\t1\n",
      "1\t1\t0\t0\t1\t0\t0\t1\t0\t0\t0\t0\t1\t0\n",
      "1\t0\t0\t1\t0\t0\t1\t1\t0\t1\t0\t0\t1\t1\n",
      "0\t0\t0\t1\t1\t0\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t0\t1\t0\t1\t1\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t1\t0\t0\t1\t0\t0\t1\t1\t1\t1\t0\n",
      "0\t1\t0\t0\t1\t1\t0\t0\t0\t0\t1\t0\t1\t0\n",
      "1\t0\t0\t0\t0\t0\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "1\t1\t1\t1\t0\t0\t0\t1\t1\t1\t0\t0\t1\t1\n",
      "0\t1\t1\t1\t0\t0\t0\t1\t1\t0\t0\t0\t1\t0\n",
      "0\t0\t1\t0\t1\t0\t0\t1\t1\t1\t1\t1\t1\t0\n",
      "0\t1\t1\t1\t0\t1\t0\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t0\t1\t1\t0\t0\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "0\t0\t1\t1\t0\t0\t0\t0\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t1\t1\t1\t0\t0\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t0\t1\t0\t1\t1\t1\t1\t0\t0\t0\t0\t1\t0\n",
      "0\t0\t1\t1\t0\t0\t0\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t0\t0\t0\t1\t0\t1\t1\t0\t0\t1\t0\n",
      "1\t1\t1\t0\t1\t0\t1\t0\t0\t1\t0\t0\t1\t0\n",
      "1\t1\t0\t0\t1\t0\t1\t0\t1\t0\t0\t1\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t0\t1\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t1\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t0\t1\t1\t0\t1\t0\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t1\t0\t1\t0\t1\t1\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t0\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t0\t1\t1\t0\t0\t0\t1\t0\t1\t0\n",
      "1\t0\t1\t0\t0\t1\t1\t1\t1\t1\t0\t0\t1\t1\n",
      "0\t1\t1\t1\t1\t0\t0\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t0\t1\t0\t1\t0\t1\t0\t1\t1\t0\t0\t1\t0\n",
      "1\t0\t1\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\t1\n",
      "1\t0\t0\t1\t0\t1\t1\t1\t1\t1\t0\t1\t1\t1\n",
      "1\t1\t0\t0\t1\t0\t1\t0\t1\t1\t1\t1\t1\t0\n",
      "0\t0\t1\t1\t1\t0\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "1\t0\t1\t1\t0\t0\t1\t0\t0\t1\t1\t1\t1\t0\n",
      "0\t0\t1\t1\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "1\t1\t1\t1\t1\t0\t0\t1\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t1\t0\t0\t0\t1\t0\t1\t0\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t1\t1\t1\t1\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t1\t0\t1\t0\t0\t1\t1\t0\n",
      "0\t1\t1\t0\t0\t0\t0\t1\t1\t1\t0\t0\t1\t0\n",
      "1\t1\t0\t0\t1\t0\t1\t0\t0\t1\t0\t0\t1\t0\n",
      "1\t0\t0\t1\t0\t1\t1\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t0\t1\t0\t0\t1\t1\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "0\t0\t1\t0\t1\t0\t1\t1\t0\t1\t1\t0\t1\t0\n",
      "1\t0\t1\t1\t1\t0\t0\t0\t0\t1\t1\t0\t1\t0\n",
      "0\t1\t1\t1\t0\t1\t0\t1\t0\t0\t1\t0\t1\t0\n",
      "1\t0\t1\t1\t1\t0\t1\t0\t1\t1\t0\t1\t1\t1\n",
      "1\t1\t1\t1\t0\t0\t0\t1\t0\t0\t0\t1\t1\t0\n",
      "0\t0\t0\t1\t1\t1\t1\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t1\t1\t0\t0\t1\t0\t0\t0\t1\t0\t1\t0\n",
      "1\t1\t0\t1\t0\t1\t1\t0\t1\t1\t0\t1\t1\t0\n",
      "1\t0\t1\t1\t1\t0\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "1\t1\t0\t0\t0\t1\t0\t0\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t1\t0\t0\t0\t1\t1\t0\t1\t1\t0\t1\t0\n",
      "1\t0\t1\t0\t0\t0\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "0\t0\t1\t0\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t1\t0\t0\t1\t0\t0\t1\t0\t1\t0\n",
      "1\t0\t1\t0\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t1\t0\t1\t1\t1\t0\t0\t1\t1\t1\t1\t1\t1\n",
      "0\t1\t1\t0\t0\t1\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t0\t1\t0\t1\t1\t1\t0\t0\t0\t0\t1\t1\t0\n",
      "1\t1\t0\t1\t0\t0\t0\t0\t1\t0\t1\t1\t1\t0\n",
      "0\t0\t1\t1\t1\t1\t1\t0\t1\t1\t1\t1\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t1\t0\t1\t0\t0\t0\t1\t0\n",
      "1\t1\t0\t0\t1\t1\t1\t1\t0\t1\t0\t1\t1\t0\n",
      "1\t0\t0\t0\t1\t1\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t0\t0\t0\t0\t1\t1\t1\t1\t1\t1\n",
      "0\t1\t0\t1\t0\t0\t1\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t1\t1\t0\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "1\t0\t0\t0\t0\t0\t0\t0\t0\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t1\t1\t1\t0\t1\t1\t1\t0\t0\t1\t0\n",
      "1\t1\t1\t0\t0\t0\t1\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t0\t1\t1\t1\t0\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t0\t1\t1\t1\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t1\t1\t1\t0\t0\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t1\t0\t0\t0\t0\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t0\t0\t1\t0\t0\t1\t0\t0\t0\t1\t1\t1\t0\n",
      "1\t0\t1\t1\t1\t1\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "1\t1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t1\t0\t1\t1\t1\t1\t1\t1\t0\t1\t0\n",
      "0\t1\t1\t1\t1\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t0\t0\t0\t1\t0\t0\t1\t1\t1\t0\n",
      "0\t0\t1\t0\t1\t0\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "1\t1\t0\t0\t0\t0\t1\t0\t1\t1\t0\t1\t1\t0\n",
      "1\t0\t1\t1\t1\t1\t0\t1\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t0\t0\t1\t1\t0\t0\t1\t0\t1\t1\t1\n",
      "1\t0\t0\t1\t0\t0\t0\t1\t1\t1\t1\t0\t1\t1\n",
      "1\t1\t0\t1\t1\t0\t0\t0\t0\t1\t1\t0\t1\t1\n",
      "1\t0\t0\t0\t1\t0\t0\t0\t1\t0\t0\t1\t1\t0\n",
      "1\t1\t0\t1\t0\t1\t0\t0\t1\t1\t1\t1\t1\t1\n",
      "1\t0\t1\t0\t1\t1\t0\t0\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t0\t1\t0\t0\t1\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t1\t0\t0\t1\t0\t1\t0\t0\t0\t1\t1\t0\n",
      "0\t0\t1\t1\t1\t0\t1\t1\t0\t1\t0\t1\t1\t1\n",
      "1\t1\t0\t0\t0\t0\t0\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t1\t0\t0\t1\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t0\t1\t1\t1\t1\t0\t1\t1\n",
      "1\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\t1\t1\t1\n",
      "0\t0\t1\t0\t0\t0\t0\t0\t0\t0\t1\t0\t1\t1\n",
      "1\t0\t0\t0\t1\t1\t0\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t1\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "0\t1\t0\t0\t1\t1\t1\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t1\t0\t0\t0\t1\t1\t1\t1\t1\t1\n",
      "1\t0\t1\t1\t1\t1\t0\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t1\t1\t1\t1\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t1\t1\t1\t0\t0\t0\t1\t0\t0\t1\t0\n",
      "1\t0\t1\t0\t0\t1\t0\t1\t1\t0\t1\t1\t1\t0\n",
      "0\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t1\t0\t1\t1\t1\t0\t1\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t0\t1\t0\t1\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t0\t1\t0\t0\t1\t1\t0\t1\t0\n",
      "1\t1\t1\t0\t0\t0\t1\t0\t0\t0\t1\t1\t1\t0\n",
      "0\t1\t0\t1\t0\t0\t0\t0\t1\t1\t0\t1\t1\t0\n",
      "1\t1\t0\t0\t0\t0\t1\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t0\t0\t1\t1\t0\t1\t0\t0\t1\t0\t0\t1\t0\n",
      "1\t1\t0\t1\t0\t0\t0\t0\t0\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t1\t1\n",
      "0\t0\t0\t1\t0\t1\t1\t1\t0\t0\t1\t0\t1\t0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1\tA2\tA3\tA4\tA5\tA6\tA7\tA8\tA9\tA10\tA11\tA12\tA13"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  2844  100  2844    0     0   5677      0 --:--:-- --:--:-- --:--:-- 17132\n",
      "100  2844  100  2844    0     0   5670      0 --:--:-- --:--:-- --:--:-- 17132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "0\t0\t0\t1\t0\t0\t1\t1\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t1\t1\t0\t1\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t0\t1\t0\n",
      "0\t1\t0\t0\t0\t1\t0\t1\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t0\t1\t1\t1\t1\t1\t1\t0\t1\t0\n",
      "0\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t0\t1\t0\t0\t1\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\t0\t1\t0\n",
      "1\t0\t1\t1\t1\t1\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "1\t0\t0\t0\t1\t0\t0\t1\t1\t0\t1\t1\t1\t0\n",
      "0\t0\t1\t0\t0\t1\t1\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t1\t1\t1\t0\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t0\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t1\t0\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "1\t0\t0\t1\t0\t0\t1\t1\t0\t0\t1\t1\t1\t0\n",
      "0\t0\t0\t1\t0\t1\t1\t0\t1\t1\t1\t1\t1\t0\n",
      "1\t0\t1\t0\t1\t1\t0\t0\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t0\t1\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t1\t0\t0\t1\t1\t1\t1\t1\t1\t0\t0\t1\t0\n",
      "1\t1\t0\t1\t0\t1\t1\t0\t1\t0\t0\t0\t1\t0\n",
      "1\t0\t1\t1\t0\t1\t0\t0\t0\t0\t1\t1\t1\t1\n",
      "1\t0\t1\t1\t1\t1\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t0\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\t1\n",
      "1\t1\t0\t1\t1\t0\t1\t1\t0\t0\t1\t0\t1\t0\n",
      "0\t0\t0\t0\t1\t1\t1\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t1\t1\t0\t0\t0\t1\t0\t0\t0\t1\t1\t1\t0\n",
      "1\t0\t1\t0\t0\t1\t0\t0\t0\t0\t1\t1\t1\t0\n",
      "1\t0\t1\t1\t1\t1\t0\t0\t0\t0\t1\t1\t1\t0\n",
      "0\t1\t0\t0\t1\t1\t1\t0\t1\t1\t0\t1\t1\t1\n",
      "0\t1\t1\t1\t0\t0\t1\t0\t1\t1\t1\t0\t1\t1\n",
      "1\t0\t0\t0\t0\t0\t0\t1\t1\t1\t1\t0\t1\t1\n",
      "1\t0\t1\t1\t0\t1\t1\t0\t0\t1\t0\t1\t1\t0\n",
      "1\t1\t1\t0\t1\t1\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "0\t1\t0\t1\t0\t1\t0\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t0\t0\t1\t0\t1\t0\t1\t1\t1\t0\t1\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t0\t0\t0\t1\t1\t0\t1\t1\n",
      "1\t0\t1\t1\t0\t1\t1\t1\t0\t0\t1\t0\t1\t0\n",
      "1\t1\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\t1\t1\n",
      "1\t1\t0\t1\t0\t0\t1\t0\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t1\t1\t0\t0\t0\t0\t0\t1\t0\t1\t1\t1\n",
      "1\t1\t1\t1\t1\t1\t1\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t0\t0\t0\t0\t1\t0\t1\t1\t1\t1\t1\t1\t1\n",
      "1\t1\t0\t1\t1\t1\t1\t0\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t1\t0\t0\t1\t1\t0\t1\t0\t1\t1\t0\n",
      "0\t0\t0\t0\t0\t1\t0\t1\t0\t1\t1\t1\t1\t0\n",
      "1\t0\t0\t1\t0\t0\t1\t1\t1\t1\t1\t1\t1\t0\n",
      "0\t1\t1\t1\t0\t1\t0\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t1\t1\t1\t0\t1\t1\t0\t0\t0\t1\t0\t1\t0\n",
      "0\t0\t0\t0\t0\t0\t1\t0\t0\t1\t0\t1\t1\t1\n",
      "0\t1\t1\t0\t1\t0\t0\t1\t0\t1\t0\t1\t1\t1\n",
      "0\t0\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "0\t1\t1\t1\t1\t0\t1\t1\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t0\t0\t0\t1\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t1\t0\t0\t0\t0\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "0\t1\t1\t0\t1\t1\t1\t0\t1\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t1\t1\t1\t0\t1\t0\t0\t1\t1\t0\n",
      "0\t0\t1\t0\t0\t0\t1\t1\t1\t1\t0\t0\t1\t1\n",
      "1\t1\t1\t1\t1\t0\t0\t0\t1\t1\t1\t0\t1\t0\n",
      "1\t0\t1\t1\t0\t1\t1\t0\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t1\t1\t1\t1\t1\t0\t0\t1\t1\t0\n",
      "1\t1\t1\t0\t0\t1\t1\t1\t0\t0\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t1\t0\t1\t0\t0\t1\t1\t1\t1\t0\n",
      "0\t0\t0\t0\t0\t0\t0\t1\t1\t0\t1\t1\t1\t0\n",
      "1\t0\t0\t0\t1\t1\t1\t1\t0\t1\t0\t0\t1\t0\n",
      "1\t1\t1\t0\t0\t0\t1\t1\t1\t1\t0\t1\t1\t0\n",
      "0\t1\t1\t0\t0\t0\t1\t1\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t0\t1\t0\t0\t0\t0\t1\t1\t1\n",
      "1\t0\t0\t1\t0\t1\t1\t1\t1\t0\t1\t0\t1\t1\n",
      "1\t1\t0\t0\t0\t0\t0\t1\t0\t1\t1\t1\t1\t1\n",
      "1\t1\t1\t0\t0\t1\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t1\t1\t1\t0\t1\t1\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t0\t1\t0\t1\t0\t0\t0\t1\t1\t1\t0\n",
      "0\t0\t0\t1\t1\t1\t1\t1\t1\t0\t0\t1\t1\t1\n",
      "1\t0\t1\t0\t1\t1\t1\t0\t1\t0\t1\t1\t1\t0\n",
      "0\t0\t0\t1\t0\t0\t0\t0\t1\t0\t1\t0\t1\t1\n",
      "0\t1\t0\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\t1\n",
      "1\t1\t0\t0\t0\t1\t0\t1\t1\t1\t0\t1\t1\t1\n",
      "1\t1\t1\t0\t0\t0\t1\t1\t0\t0\t1\t1\t1\t0\n",
      "1\t1\t1\t1\t1\t0\t1\t0\t0\t0\t1\t0\t1\t0\n",
      "1\t1\t1\t0\t0\t0\t1\t0\t0\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t0\t1\t1\t1\t1\t0\t1\t0\t1\t1\t0\n",
      "0\t1\t1\t1\t0\t1\t1\t0\t0\t1\t1\t1\t1\t0\n",
      "1\t1\t1\t1\t1\t1\t1\t0\t0\t0\t1\t0\t1\t0\n",
      "0\t1\t1\t0\t0\t0\t1\t1\t1\t0\t1\t0\t1\t1\n",
      "0\t1\t0\t1\t0\t0\t0\t1\t0\t0\t1\t0\t1\t0\n",
      "1\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t0\t0\t0\t1\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "0\t1\t0\t0\t0\t1\t0\t0\t0\t1\t1\t0\t1\t1\n",
      "1\t1\t1\t1\t0\t1\t0\t0\t1\t0\t0\t0\t1\t0\n",
      "0\t0\t1\t1\t1\t1\t0\t0\t0\t0\t0\t1\t1\t1\n",
      "0\t1\t1\t1\t1\t0\t0\t1\t0\t0\t0\t1\t1\t0\n",
      "1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t0\t1\t1\t0\n",
      "1\t1\t1\t0\t1\t0\t0\t1\t0\t0\t1\t1\t1\t0\n",
      "1\t0\t1\t0\t1\t1\t1\t1\t0\t0\t1\t1\t1\t0\n",
      "0\t1\t0\t1\t0\t1\t1\t0\t0\t1\t1\t0\t1\t0\n",
      "1\t0\t0\t1\t0\t0\t0\t1\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t1\t0\t1\t1\t1\t0\t0\t0\t1\t0\t1\t0\n",
      "1\t1\t1\t1\t0\t0\t0\t1\t1\t1\t1\t1\t1\t0\n",
      "1\t0\t1\t1\t0\t1\t1\t1\t0\t1\t1\t0\t1\t0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the datasets\n",
    "!curl.exe http://huang.eng.unt.edu/CSCE-5218/train.dat\n",
    "!curl.exe http://huang.eng.unt.edu/CSCE-5218/test.dat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A69DxPSc8vNs",
    "outputId": "5440e602-8ecd-44cf-d48d-2e8b00cdcc52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 11244  100 11244    0     0  39568      0 --:--:-- --:--:-- --:--:-- 41338\n",
      "100 11244  100 11244    0     0  39517      0 --:--:-- --:--:-- --:--:-- 41186\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  2844  100  2844    0     0   3835      0 --:--:-- --:--:-- --:--:-- 11421\n"
     ]
    }
   ],
   "source": [
    "# Take a peek at the datasets\n",
    "!curl --output train.dat http://huang.eng.unt.edu/CSCE-5218/train.dat\n",
    "!curl --output test.dat http://huang.eng.unt.edu/CSCE-5218/test.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFXHLhnhwiBR"
   },
   "source": [
    "### Build the Perceptron Model\n",
    "\n",
    "You will need to complete some of the function definitions below.  DO NOT import any other libraries to complete this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "cXAsP_lw3QwJ"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "# Corpus reader, all columns but the last one are coordinates;\n",
    "#   the last column is the label\n",
    "def read_data(file_name):\n",
    "    f = open(file_name, 'r')\n",
    "\n",
    "    data = []\n",
    "    # Discard header line\n",
    "    f.readline()\n",
    "    for instance in f.readlines():\n",
    "        if not re.search('\\t', instance): continue\n",
    "        instance = list(map(int, instance.strip().split('\\t')))\n",
    "        # Add a dummy input so that w0 becomes the bias\n",
    "        #print(instance)\n",
    "        #print(\"after readline\")\n",
    "        instance = [-1] + instance\n",
    "        #print(instance)\n",
    "        data += [instance]\n",
    "    return data\n",
    "\n",
    "\n",
    "def dot_product(array1, array2):\n",
    "    dot_product = 0\n",
    "    for i,j in zip(array1,array2):\n",
    "        dot_product = dot_product + (i * j)\n",
    "    return dot_product\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return (1.0 / (1.0 + math.exp(-1.0*x)))\n",
    "\n",
    "# The output of the model, which for the perceptron is \n",
    "# the sigmoid function applied to the dot product of \n",
    "# the instance and the weights\n",
    "def output(weight, instance):\n",
    "    output = sigmoid(dot_product(weight, instance))\n",
    "    return output\n",
    "\n",
    "# Predict the label of an instance; this is the definition of the perceptron\n",
    "# you should output 1 if the output is >= 0.5 else output 0\n",
    "def predict(weights, instance):\n",
    "    if output(weights, instance) >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Accuracy = percent of correct predictions\n",
    "def get_accuracy(weights, instances):\n",
    "    # You do not to write code like this, but get used to it\n",
    "    correct = sum([1 if predict(weights, instance) == instance[-1] else 0\n",
    "                   for instance in instances])\n",
    "    return correct * 100 / len(instances)\n",
    "\n",
    "\n",
    "# Train a perceptron with instances and hyperparameters:\n",
    "#       lr (learning rate) \n",
    "#       epochs\n",
    "# The implementation comes from the definition of the perceptron\n",
    "#\n",
    "# Training consists on fitting the parameters which are the weights\n",
    "# that's the only thing training is responsible to fit\n",
    "# (recall that w0 is the bias, and w1..wn are the weights for each coordinate)\n",
    "#\n",
    "# Hyperparameters (lr and epochs) are given to the training algorithm\n",
    "# We are updating weights in the opposite direction of the gradient of the error,\n",
    "# so with a \"decent\" lr we are guaranteed to reduce the error after each iteration.\n",
    "def train_perceptron(instances, lr, epochs):\n",
    "\n",
    "    #TODO: name this step\n",
    "    weights = [0] * (len(instances[0]))\n",
    "    #print(weights)\n",
    "    for _ in range(epochs):\n",
    "        for instance in instances:\n",
    "            #TODO: name these steps\n",
    "            #print(instance)\n",
    "            #print(weights)\n",
    "            in_value = dot_product(weights, instance)\n",
    "            #print(in_value)\n",
    "            #print(\"--------------------\")\n",
    "            output = sigmoid(in_value)\n",
    "            error = instance[-1] - output\n",
    "            #TODO: name these steps\n",
    "            for i in range(0, len(weights)):\n",
    "                weights[i] += lr * error * output * (1-output) * instance[i]\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adBZuMlAwiBT"
   },
   "source": [
    "## Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "50YvUza-BYQF",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19834690842618988, -0.047528630608296846, -0.07445715046174368, -0.05847954338095892, -0.06206714117763581, -0.11731257435626952, -0.10312217725648434, -0.1786193849564548, -0.06766220948749965, -0.01690275153925823, -0.025589272102902735, 0.05420153371311189, -0.14840632708386856, -0.19834690842618988, 0.3941623144280716]\n",
      "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n"
     ]
    }
   ],
   "source": [
    "instances_tr = read_data(\"train.dat\")\n",
    "instances_te = read_data(\"test.dat\")\n",
    "lr = 0.005\n",
    "epochs = 5\n",
    "\n",
    "#print(instances_tr[0])\n",
    "\n",
    "weights = train_perceptron(instances_tr, lr, epochs)\n",
    "print(weights)\n",
    "accuracy = get_accuracy(weights, instances_te)\n",
    "print(f\"#tr: {len(instances_tr):3}, epochs: {epochs:3}, learning rate: {lr:.3f}; \"\n",
    "      f\"Accuracy (test, {len(instances_te)} instances): {accuracy:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBXkvaiQMohX"
   },
   "source": [
    "## Questions\n",
    "\n",
    "Answer the following questions. Include your implementation and the output for each question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCQ6BEk1CBlr"
   },
   "source": [
    "\n",
    "\n",
    "### Question 1\n",
    "\n",
    "In `train_perceptron(instances, lr, epochs)`, we have the follosing code:\n",
    "```\n",
    "in_value = dot_product(weights, instance)\n",
    "output = sigmoid(in_value)\n",
    "error = instance[-1] - output\n",
    "```\n",
    "\n",
    "Why don't we have the following code snippet instead?\n",
    "```\n",
    "output = predict(weights, instance)\n",
    "error = instance[-1] - output\n",
    "```\n",
    "\n",
    "#### Answer\n",
    "At each instance, the input is calculated based on the weight associated with it. Then the sigmoid function needs to be applied on the input to calculate the gradient decent to finally calculate the error. This process repeats until the error is at the required minimum threshold.\n",
    "\n",
    "So using the the following code snippet,\n",
    "in_value = dot_product(weights, instance)\n",
    "output = sigmoid(in_value)\n",
    "error = instance[-1] - output\n",
    "\n",
    "we are calculating more accurate weights which yeilds better learning rate and accuracy.\n",
    "\n",
    "weights:\n",
    "[0.19834690842618988, -0.047528630608296846, -0.07445715046174368, -0.05847954338095892, -0.06206714117763581, -0.11731257435626952, -0.10312217725648434, -0.1786193849564548, -0.06766220948749965, -0.01690275153925823, -0.025589272102902735, 0.05420153371311189, -0.14840632708386856, -0.19834690842618988, 0.3941623144280716]\n",
    "output:\n",
    "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "\n",
    "When using the following code snippet, the weights are not calculated correctly.\n",
    "output = predict(weights, instance)\n",
    "error = instance[-1] - output\n",
    "\n",
    "weights:\n",
    "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JU3c3m6YL2rK"
   },
   "source": [
    "### Question 2\n",
    "Train the perceptron with the following hyperparameters and calculate the accuracy with the test dataset.\n",
    "\n",
    "```\n",
    "tr_percent = [5, 10, 25, 50, 75, 100] # percent of the training dataset to train with\n",
    "num_epochs = [5, 10, 20, 50, 100]              # number of epochs\n",
    "lr = [0.005, 0.01, 0.05]              # learning rate\n",
    "```\n",
    "\n",
    "TODO: Write your code below and include the output at the end of each training loop (NOT AFTER EACH EPOCH)\n",
    "of your code.The output should look like the following:\n",
    "```\n",
    "# tr:  20, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "# tr:  20, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "# tr:  20, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "[and so on for all the combinations]\n",
    "```\n",
    "You will get different results with different hyperparameters.\n",
    "\n",
    "#### TODO Add your answer here (code and output in the format above) \n",
    "Hyperparameters:\n",
    "tr_percent = [5, 10, 25, 50, 75, 100] # percent of the training dataset to train with\n",
    "num_epochs = [5, 10, 20, 50, 100]     # number of epochs\n",
    "lr_array = [0.005, 0.01, 0.05]        # learning rate\n",
    "\n",
    "Output:\n",
    "#tr: 20, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 74.0\n",
    "#tr: 40, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "#tr: 100, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 92.0\n",
    "#tr: 200, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 100.0\n",
    "#tr: 300, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 100.0\n",
    "#tr: 400, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 100.0\n",
    "#tr: 20, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 85.0\n",
    "#tr: 40, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 80.0\n",
    "#tr: 100, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 98.0\n",
    "#tr: 200, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 100.0\n",
    "#tr: 300, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 100.0\n",
    "#tr: 400, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 100.0\n",
    "#tr: 20, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 91.0\n",
    "#tr: 40, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 97.0\n",
    "#tr: 100, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 100.0\n",
    "#tr: 200, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 100.0\n",
    "#tr: 300, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 100.0\n",
    "#tr: 400, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 100.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "G-VKJOUu2BTp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#tr: 20, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 74.0\n",
      "#tr: 40, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 92.0\n",
      "#tr: 200, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 100.0\n",
      "#tr: 300, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 100.0\n",
      "#tr: 400, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 100.0\n",
      "#tr: 20, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 85.0\n",
      "#tr: 40, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 80.0\n",
      "#tr: 100, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 98.0\n",
      "#tr: 200, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 100.0\n",
      "#tr: 300, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 100.0\n",
      "#tr: 400, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 100.0\n",
      "#tr: 20, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 91.0\n",
      "#tr: 40, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 97.0\n",
      "#tr: 100, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 100.0\n",
      "#tr: 200, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 100.0\n",
      "#tr: 300, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 100.0\n",
      "#tr: 400, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 100.0\n"
     ]
    }
   ],
   "source": [
    "instances_tr = read_data(\"train.dat\")\n",
    "instances_te = read_data(\"test.dat\")\n",
    "tr_percent = [5, 10, 25, 50, 75, 100] # percent of the training dataset to train with\n",
    "num_epochs = [5, 10, 20, 50, 100]     # number of epochs\n",
    "lr_array = [0.005, 0.01, 0.05]        # learning rate\n",
    "\n",
    "for lr in lr_array:\n",
    "  for tr_size in tr_percent:\n",
    "    for epochs in num_epochs:\n",
    "      size =  round(len(instances_tr)*tr_size/100)\n",
    "      pre_instances = instances_tr[0:size]\n",
    "      weights = train_perceptron(pre_instances, lr, epochs)\n",
    "      accuracy = get_accuracy(weights, instances_te)\n",
    "    print(f\"#tr: {len(pre_instances):0}, epochs: {epochs:3}, learning rate: {lr:.3f}; \"\n",
    "            f\"Accuracy (test, {len(instances_te)} instances): {accuracy:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFB9MtwML24O"
   },
   "source": [
    "### Question 3\n",
    "Write a couple paragraphs interpreting the results with all the combinations of hyperparameters. Drawing a plot will probably help you make a point. In particular, answer the following:\n",
    "- A. Do you need to train with all the training dataset to get the highest accuracy with the test dataset?\n",
    "     Answer: The best practise is to use the full training dataset to train the model so the model can learn complete charecteristcs of the data. Sometimes, the full dataset can be massive and can take large amount of time. So, one can make the judgement on how much data is a good representation of the training data inorder to achieve desired accuracy. The recommended approach is to allocate 80% of training dataset for traning and 20% for testing.\n",
    "     \n",
    "- B. How do you justify that training the second run obtains worse accuracy than the first one (despite the second one uses more training data)?\n",
    "     Answer: Clearly, the second run used twice the size of training data compared to first run but the second run yielded lower accuracy than first. This indicates that more training data doesn't always mean better accuracy. It implies that the model have been overfit and not performing well to new data.\n",
    "     The hyperparameters used also makes a difference on the accuracy. The lr parameter value may also played a role in lower accuracy of the second run. So one should fine tune the hyperparameters to attain reasonable accuracy.\n",
    "   ```\n",
    "#tr: 100, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 71.0\n",
    "#tr: 200, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "```\n",
    "- C. Can you get higher accuracy with additional hyperparameters (higher than `80.0`)?\n",
    "     Answer: Additional hyperparameters may not necessarily get higher accuracy. By fine tuning the hyperparameters we may be able to achieve higher accuracy.\n",
    "     \n",
    "- D. Is it always worth training for more epochs (while keeping all other hyperparameters fixed)?\n",
    "     Answer: It is not always a good idea to train the model for more epochs while keeping all other hyperparameters. Fine tuning the model performance is an iterative process. This is achieved by trying out various combinations of hyperparameters to achieve desired accuracy. \n",
    "     \n",
    "#### TODO: Add your answer here (code and text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38rA_Kp3wiBX"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW2_The_Perceptron.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
